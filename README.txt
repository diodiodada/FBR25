关于梯度更新的方案：

第一种方案：不分享权重，每一个网络单独训练，然后在这25个网络中挑取最优的

第二种方案：权重共享，但是每次训练25个图中只有一个图有输入，其他的图没有输入，更新完一次权重后轮换到下一个图

第三种方案：权重共享，但与2不同，这时25个图都有相同的输入，然后分别求每一个图的梯度，得到25组梯度，然后把他们相加求平均，最后完成一次更新

第四种方案：从这25张图中选取n张图（n未知），然后采取第二种或者第三种方案进行训练

还有一种不太清楚的特殊情况就是：keras 自动对由25张图构成的大图进行了剪枝，减去了重复的边，这种情况可以看成是对25个小图的loss更改了加权


还有，我发现了一些 keras 自带画图工具的不足：
如果 layer(or model) A 和 layer(or model) B 共享权重，并且 A 和 B 的输入是一样的话，用 plot_model 画图会失败，
而且若这时A和B的输出直接接着网络的输出，feed 数据时 keras 会警告“The list of outputs passed to the model is redundant”
如果 layer(or model) A 和 layer(or model) B 共享权重，并且 A 和 B 的输入不一样，用 plot_model 画图仍然会失败，
但是若这时A和B的输出直接接着网络的输出，feed 数据时 keras 不会产生这样的警告

当我使用 tensorboard 画图时，共享权重画图不会失败，但是画出来的图仍待解释

还有就是对于我这个任务来说：
若我不使用cell机制，那么模型保存的权重文件大小是：一个cell所需权重大小的15倍
若我使用cell机制，那么模型保存的权重文件大小是：一个cell所需权重大小


我发现了一个现象，就是不分享权重，每一个网络单独训练，然后把每一个网络的输出取平均收敛的很快，但这样做的没什么意义，因为实际应用的时候我们需要的
是单独的把某一个网络的某一个模型拿出来用。
所以测试权重不共享的情况的时候应该把每一个网络的每一个模块单独拿出来测试，然后寻找最优的。

新想法：这25个网络可以串联也可以并联，若选择并联，网络可以进一步约减

新实验：直接让网络的state为图片，同时输出state的网络也直接输出图片

关于需不需要对不同网络输出的结果进行平均，来使网络的输出结果降低到3？
这里猜想是不可以的，因为可能会出现这样的情况，但采用 mse 的 loss 时，某一个网络A的输出结果偏高，另一个网络的B输出结果偏低，
一平均，loss反而接近0，这是loss对网络A和网络B的梯度都会因为对方的影响而降低


发现在多输出网络模型中，自定义的 metrics 中的 y_true, y_pred 是代表多输出中的任意一个，而不是代表全部输出的list，
所以无法通过自定义metrics来只评估某几个输出而忽略其他的输出。因为定义的 metrics 函数会循环作用在所有的输出上

发现 keras 的一个很烦人的特性，就是在多输出模型时，明明输出有3*8=24个（8个网络共享权重，模型名称相同），
但是训练过程中展示出来的 loss 却只有3个，而不是24个，但是metrics展示出来的的确是24个


!!!! 最终章：

实验失败，因为实现发现把25个模型并联的效果不如分别训练 forward net, backward net and recover net。
其实这也好理解，因为把三个模型串联起来的时候引入了累计误差，也就是说三个模型中的某个的输出会成为其他模型的输入，
然而这个输入相对于真实值是有误差的，这就相当于人为的在数据中添加了噪声，训练之后在测试集上的效果就当然没有直接在没有噪声的数据上训练的效果好了。

实验方法为：
运行 newest.py 或者 newest_share_feature.py 代码

实验 1：
执行 train(model_simple, 'simple') 开始分别训练forward net, backward net and recover net。
执行 test(model_simple, 'simple') 开始在测试集上测试forward net, backward net and recover net 的表现。

实验 2：
执行 train(model_complex, 'complex') 开始训练 3-input 24-output with-cell using-set 的模型。
执行 test(model_simple, 'complex') 开始在测试集上分别测试forward net, backward net and recover net 的表现。

发现一：

    结果为 实验2 的结果永远比 实验1 的结果要差。
    但是其实实验2中的模型结构是包含实验1的，所以————
    当在 实验2 中，设置 loss_weights=[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] * 3 时，结果就 实验1 一样了

发现二：

    当使用同样的模型时，运行 newest_share_feature.py 得到的模型要比运行 newest.py 得到的模型结果要好
    newest_share_feature.py 与 newest.py 代码的唯一区别在于 newest_share_feature.py 使用共享特征层，
    这说明在共享某一些网络层的权重的时候通过增加辅助网络来联合训练的确是有意义的